{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bad6c9f",
   "metadata": {},
   "source": [
    "# Day 5 NLP 's practice Assignments:\n",
    "    1.Build a Question answering model with Transformers from huggingface.\n",
    "    2.Build a Translation model using transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799140b7",
   "metadata": {},
   "source": [
    "#    1.Build a Question answering model with Transformers from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def run_qa_model(context, question):\n",
    "    # Load the question answering model\n",
    "    qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "    # Get the answer using the question answering model\n",
    "    answer = qa_model(question=question, context=context)\n",
    "\n",
    "    # Print the answer\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", answer['answer'])\n",
    "    print(\"Score:\", answer['score'])\n",
    "    print(\"Start index:\", answer['start'])\n",
    "    print(\"End index:\", answer['end'])\n",
    "\n",
    "\n",
    "context = \"Hugging Face is a company that specializes in Natural Language Processing models.\"\n",
    "\n",
    "# Asking a series of questions\n",
    "questions = [\n",
    "    \"What does Hugging Face specialize in?\",\n",
    "    \"Who founded Hugging Face?\",\n",
    "    \"When was Hugging Face established?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1bae2",
   "metadata": {},
   "source": [
    "# 2.Build a Translation model using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac09d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476bdd29b27e415abde649e20ecb7f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e69c8d80a5043e681ff69169839b528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a234389ef24aae82c287cde6661351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dc5ae7582d4fbe97c857026cbe31fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48221f1a7a4448a952e6e9ee2ea5005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09b8f99248b4133b82331772ac998ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3b65f967a14028bf4a0788a78f19ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Text (en): Hello, how are you?\n",
      "Translated Text (fr): Bonjour, comment allez-vous ?\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def run_translation_model(text, source_lang, target_lang):\n",
    "    # Load the translation model\n",
    "    translator = pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\")\n",
    "\n",
    "    # Translate the text\n",
    "    translated_text = translator(text, max_length=500)[0]['translation_text']\n",
    "\n",
    "    # Print the translated text\n",
    "    print(f\"Source Text ({source_lang}): {text}\")\n",
    "    print(f\"Translated Text ({target_lang}): {translated_text}\")\n",
    "\n",
    "# Example English text\n",
    "english_text = \"Hello, how are you?\"\n",
    "\n",
    "# Translate from English to French\n",
    "run_translation_model(english_text, source_lang=\"en\", target_lang=\"fr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
