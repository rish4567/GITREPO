{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e12281b",
   "metadata": {},
   "source": [
    "# Day6-NLP Practice Assignment\n",
    "    1.\tBuild a NLP Language model for text generation involves train a neural network to predict the next word in a sequence of words.\n",
    "    2.\tBuild a Speech to Text model.\n",
    "    3.\tBuild a Text to Speech model.\n",
    "    4.\tBuild a NLP Language model to detect the sentence/word error in the text corpus.\n",
    "    5.\tBuild a Language model to correct the error in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0948e7",
   "metadata": {},
   "source": [
    "# 1.\tBuild a NLP Language model for text generation involves train a neural network to predict the next word in a sequence of words.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d20893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 4s - loss: 2.6363 - accuracy: 0.0833 - 4s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 2.6278 - accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 2.6190 - accuracy: 0.3333 - 17ms/epoch - 17ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 2.6100 - accuracy: 0.4167 - 12ms/epoch - 12ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 2.6007 - accuracy: 0.3333 - 10ms/epoch - 10ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 2.5909 - accuracy: 0.3333 - 10ms/epoch - 10ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 2.5806 - accuracy: 0.3333 - 12ms/epoch - 12ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 2.5697 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 2.5579 - accuracy: 0.3333 - 11ms/epoch - 11ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 2.5453 - accuracy: 0.3333 - 10ms/epoch - 10ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 2.5316 - accuracy: 0.3333 - 11ms/epoch - 11ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 2.5168 - accuracy: 0.3333 - 11ms/epoch - 11ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 2.5006 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 2.4829 - accuracy: 0.1667 - 10ms/epoch - 10ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 2.4637 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 2.4427 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 2.4199 - accuracy: 0.1667 - 14ms/epoch - 14ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 2.3954 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 2.3691 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 2.3415 - accuracy: 0.1667 - 14ms/epoch - 14ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 2.3130 - accuracy: 0.1667 - 13ms/epoch - 13ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 2.2846 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 2.2570 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 2.2313 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 2.2073 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 2.1839 - accuracy: 0.1667 - 14ms/epoch - 14ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 2.1590 - accuracy: 0.1667 - 11ms/epoch - 11ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 2.1307 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 2.0984 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 2.0625 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 2.0240 - accuracy: 0.1667 - 12ms/epoch - 12ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 1.9843 - accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 1.9439 - accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 1.9028 - accuracy: 0.5000 - 32ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 1.8604 - accuracy: 0.6667 - 14ms/epoch - 14ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 1.8158 - accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 1.7679 - accuracy: 0.8333 - 9ms/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 1.7164 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 1.6613 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 1.6035 - accuracy: 0.9167 - 11ms/epoch - 11ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 1.5438 - accuracy: 0.9167 - 11ms/epoch - 11ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 1.4830 - accuracy: 0.8333 - 13ms/epoch - 13ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 1.4214 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 1.3588 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 1.2954 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 1.2319 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 1.1695 - accuracy: 0.8333 - 11ms/epoch - 11ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 1.1089 - accuracy: 0.8333 - 15ms/epoch - 15ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 1.0504 - accuracy: 0.8333 - 12ms/epoch - 12ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.9937 - accuracy: 0.9167 - 11ms/epoch - 11ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.9390 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.8863 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.8351 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.7851 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.7364 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.6898 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.6457 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.6045 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.5664 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.5309 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.4973 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.4659 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.4361 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.4078 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.3813 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.3571 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.3350 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.3144 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.2950 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.2767 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.2591 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.2424 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.2269 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.2127 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1997 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1877 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1766 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1663 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1566 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1478 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1395 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1320 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1250 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1185 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1124 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1067 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1013 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.0963 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.0915 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.0870 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.0828 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.0789 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.0753 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.0718 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.0686 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.0656 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.0627 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.0600 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.0575 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.0551 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "The quick brown fox fox jumps dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample data\n",
    "corpus = [\n",
    "    \"The quick brown fox\",\n",
    "    \"jumps over the lazy dog\",\n",
    "    \"She sells seashells by the seashore\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences and targets\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "x, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, epochs=100, verbose=2)\n",
    "\n",
    "# Generate text completion\n",
    "seed_text = \"The quick\"\n",
    "next_words = 5\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "\n",
    "    predicted = np.argmax(model.predict(token_list, verbose=0))\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a761e",
   "metadata": {},
   "source": [
    "# 2.\tBuild a Speech to Text model.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d524268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something:\n",
      "Text from speech: hello\n"
     ]
    }
   ],
   "source": [
    "#pip install pyaudio\n",
    "#pip install SpeechRecognition\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "def speech_to_text():\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something:\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"Text from speech:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    speech_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6087e57",
   "metadata": {},
   "source": [
    "# 3.\tBuild a Text to Speech model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df84b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text for Text-to-Speech: hiii how are you\n"
     ]
    }
   ],
   "source": [
    "# pip install gtts\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "def text_to_speech(text, language='en', filename='output.mp3'):\n",
    "    tts = gTTS(text=text, lang=language, slow=False)\n",
    "    tts.save(filename)\n",
    "    os.system(f\"start {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = input('Enter text for Text-to-Speech: ')\n",
    "    text_to_speech(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ad837",
   "metadata": {},
   "source": [
    "# 4.\tBuild a NLP Language model to detect the sentence/word error in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653695fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 33.33%\n",
      "Prediction for 'hello': Correct\n",
      "Prediction for 'helo': Incorrect\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Sample dataset of correctly spelled and misspelled words\n",
    "correct_words = ['hello', 'world', 'python', 'spell', 'language', 'model', 'check']\n",
    "misspelled_words = ['helo', 'worl', 'pythoon', 'spl', 'langage', 'moel', 'chek']\n",
    "\n",
    "# Combine correct and misspelled words into a single dataset\n",
    "all_words = correct_words + misspelled_words\n",
    "\n",
    "# Labels (1 for correct, 0 for incorrect)\n",
    "labels = [1] * len(correct_words) + [0] * len(misspelled_words)\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)  # Remove single characters\n",
    "    return text.lower()\n",
    "\n",
    "all_words = [preprocess_text(word) for word in all_words]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_words, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the words with Bag of Words representation\n",
    "cv = CountVectorizer()\n",
    "x_train_cv = cv.fit_transform(x_train)\n",
    "x_test_cv = cv.transform(x_test)\n",
    "\n",
    "# Classifier model with Naive Bayes Algorithm\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_cv, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = clf.predict(x_test_cv)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Test the model with new examples\n",
    "def detect_error(text):\n",
    "    text = preprocess_text(text)\n",
    "    text_cv = cv.transform([text])\n",
    "    prediction = clf.predict(text_cv)\n",
    "    return \"Correct\" if prediction[0] == 1 else \"Incorrect\"\n",
    "\n",
    "#input text\n",
    "text1 = \"hello\"\n",
    "text2 = \"helo\"\n",
    "\n",
    "print(f\"Prediction for '{text1}': {detect_error(text1)}\")\n",
    "print(f\"Prediction for '{text2}': {detect_error(text2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4d5c1",
   "metadata": {},
   "source": [
    "# 5.\tBuild a Language model to correct the error in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def correct_errors_language_model(text):\n",
    "    # Load pre-trained GPT-2 model and tokenizer\n",
    "    model_name = 'gpt2'\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    # Generate corrected text using the language model\n",
    "    output = model.generate(input_ids, max_length=150, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "    # Decode the generated tokens back to text\n",
    "    corrected_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(input_text)\n",
    "print(\"\\nCorrected Text:\")\n",
    "print(corrected_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
